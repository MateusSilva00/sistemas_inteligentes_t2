{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando somente 1 neurônio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teteus/Documents/sistemas_inteligentes/trabalho02/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1942.5039 - mae: 41.1112\n",
      "Epoch 2/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1512.2466 - mae: 35.8441\n",
      "Epoch 3/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1233.3629 - mae: 31.6747\n",
      "Epoch 4/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1027.0790 - mae: 28.7427\n",
      "Epoch 5/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 803.7422 - mae: 24.7806\n",
      "Epoch 6/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 693.1913 - mae: 22.7902\n",
      "Epoch 7/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 549.1854 - mae: 19.9597\n",
      "Epoch 8/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 428.9346 - mae: 17.1385\n",
      "Epoch 9/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380.3535 - mae: 15.9337\n",
      "Epoch 10/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 323.3878 - mae: 14.6147\n",
      "Epoch 11/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 264.2952 - mae: 13.1228\n",
      "Epoch 12/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 241.9617 - mae: 12.6549\n",
      "Epoch 13/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 243.2273 - mae: 12.6151\n",
      "Epoch 14/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222.4532 - mae: 12.0389\n",
      "Epoch 15/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.5949 - mae: 11.5260\n",
      "Epoch 16/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.2200 - mae: 11.5181\n",
      "Epoch 17/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.9612 - mae: 11.3429\n",
      "Epoch 18/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.3209 - mae: 11.6235\n",
      "Epoch 19/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.9335 - mae: 11.0351\n",
      "Epoch 20/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.0292 - mae: 11.6381\n",
      "Epoch 21/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.9000 - mae: 11.7019\n",
      "Epoch 22/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.9103 - mae: 11.7483\n",
      "Epoch 23/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.2874 - mae: 11.2772\n",
      "Epoch 24/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.3438 - mae: 11.7822\n",
      "Epoch 25/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.4888 - mae: 11.6577\n",
      "Epoch 26/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 220.3972 - mae: 11.8837\n",
      "Epoch 27/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 198.9615 - mae: 11.4138\n",
      "Epoch 28/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.6234 - mae: 11.6897\n",
      "Epoch 29/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.7268 - mae: 11.5764\n",
      "Epoch 30/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.1939 - mae: 11.6024\n",
      "Epoch 31/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.7665 - mae: 11.3797\n",
      "Epoch 32/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.9386 - mae: 11.2858\n",
      "Epoch 33/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.1321 - mae: 11.6065\n",
      "Epoch 34/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 196.9077 - mae: 11.2005\n",
      "Epoch 35/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.6578 - mae: 11.6925\n",
      "Epoch 36/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.0457 - mae: 11.5270\n",
      "Epoch 37/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.2735 - mae: 11.3605\n",
      "Epoch 38/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.2732 - mae: 11.2874\n",
      "Epoch 39/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.2541 - mae: 11.6311\n",
      "Epoch 40/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.6843 - mae: 11.5843\n",
      "Epoch 41/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.6117 - mae: 11.4328\n",
      "Epoch 42/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.4759 - mae: 11.4333\n",
      "Epoch 43/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 222.0753 - mae: 11.9362\n",
      "Epoch 44/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.9239 - mae: 11.1621\n",
      "Epoch 45/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.3568 - mae: 11.7598\n",
      "Epoch 46/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.8090 - mae: 11.5344\n",
      "Epoch 47/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.2921 - mae: 11.5714\n",
      "Epoch 48/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 192.6750 - mae: 11.0636\n",
      "Epoch 49/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.6481 - mae: 11.5365\n",
      "Epoch 50/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.3677 - mae: 11.4382\n",
      "Epoch 51/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.3485 - mae: 11.4177\n",
      "Epoch 52/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.5607 - mae: 11.3029\n",
      "Epoch 53/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 191.0770 - mae: 11.0450\n",
      "Epoch 54/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 201.7842 - mae: 11.4461\n",
      "Epoch 55/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.5167 - mae: 11.3246\n",
      "Epoch 56/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 193.2827 - mae: 11.1449\n",
      "Epoch 57/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.5851 - mae: 11.5781\n",
      "Epoch 58/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.6146 - mae: 11.3671\n",
      "Epoch 59/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 189.1263 - mae: 10.8768\n",
      "Epoch 60/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.2037 - mae: 11.7904\n",
      "Epoch 61/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.8143 - mae: 11.2213\n",
      "Epoch 62/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 210.1528 - mae: 11.6726\n",
      "Epoch 63/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 205.3490 - mae: 11.4380\n",
      "Epoch 64/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.4311 - mae: 11.5439\n",
      "Epoch 65/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.7303 - mae: 11.1602\n",
      "Epoch 66/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.3963 - mae: 11.5941\n",
      "Epoch 67/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.1798 - mae: 11.7348\n",
      "Epoch 68/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 213.0369 - mae: 11.6391\n",
      "Epoch 69/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.4582 - mae: 11.7754\n",
      "Epoch 70/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 218.3887 - mae: 11.9497\n",
      "Epoch 71/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.3983 - mae: 11.4111\n",
      "Epoch 72/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 223.5457 - mae: 11.8732\n",
      "Epoch 73/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.9315 - mae: 11.3066\n",
      "Epoch 74/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.5589 - mae: 11.2333\n",
      "Epoch 75/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.7043 - mae: 11.7597\n",
      "Epoch 76/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.5655 - mae: 11.5874\n",
      "Epoch 77/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.0570 - mae: 11.6586\n",
      "Epoch 78/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 216.1516 - mae: 11.8735\n",
      "Epoch 79/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 210.8831 - mae: 11.5611\n",
      "Epoch 80/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.6745 - mae: 11.7223\n",
      "Epoch 81/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.4554 - mae: 11.3403\n",
      "Epoch 82/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.0510 - mae: 11.5757\n",
      "Epoch 83/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.3367 - mae: 11.5720\n",
      "Epoch 84/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.7091 - mae: 11.6465\n",
      "Epoch 85/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.5784 - mae: 11.7137\n",
      "Epoch 86/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.2466 - mae: 11.6743\n",
      "Epoch 87/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.2603 - mae: 11.7038\n",
      "Epoch 88/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.4387 - mae: 11.1106\n",
      "Epoch 89/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.6910 - mae: 11.5148\n",
      "Epoch 90/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.4528 - mae: 11.3341\n",
      "Epoch 91/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.0355 - mae: 11.2550\n",
      "Epoch 92/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.4661 - mae: 11.4299\n",
      "Epoch 93/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.7338 - mae: 11.3392\n",
      "Epoch 94/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 210.3788 - mae: 11.5265\n",
      "Epoch 95/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.1892 - mae: 11.2534\n",
      "Epoch 96/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.0111 - mae: 11.6736\n",
      "Epoch 97/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.4800 - mae: 11.1149\n",
      "Epoch 98/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.0684 - mae: 11.5174\n",
      "Epoch 99/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.2148 - mae: 11.2097\n",
      "Epoch 100/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.8749 - mae: 11.3952\n",
      "Epoch 101/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.8313 - mae: 11.5481\n",
      "Epoch 102/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.2225 - mae: 11.1455\n",
      "Epoch 103/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.7785 - mae: 11.6921\n",
      "Epoch 104/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.0974 - mae: 11.2163\n",
      "Epoch 105/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.0304 - mae: 11.4248\n",
      "Epoch 106/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 218.0141 - mae: 11.8686\n",
      "Epoch 107/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.8899 - mae: 11.4724\n",
      "Epoch 108/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.2270 - mae: 11.4183\n",
      "Epoch 109/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.5048 - mae: 11.6852\n",
      "Epoch 110/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.4738 - mae: 11.3782\n",
      "Epoch 111/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.4117 - mae: 11.5825\n",
      "Epoch 112/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.3945 - mae: 11.5164\n",
      "Epoch 113/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 203.2144 - mae: 11.4820\n",
      "Epoch 114/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.9462 - mae: 11.3317\n",
      "Epoch 115/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.6005 - mae: 11.6676\n",
      "Epoch 116/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.2287 - mae: 11.7636\n",
      "Epoch 117/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.1013 - mae: 11.7627\n",
      "Epoch 118/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.7437 - mae: 11.4279\n",
      "Epoch 119/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.8828 - mae: 11.6276\n",
      "Epoch 120/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 198.8146 - mae: 11.3491\n",
      "Epoch 121/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.3364 - mae: 11.7223\n",
      "Epoch 122/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 213.8987 - mae: 11.5960\n",
      "Epoch 123/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.5596 - mae: 11.5683\n",
      "Epoch 124/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.0754 - mae: 11.6522\n",
      "Epoch 125/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.2999 - mae: 11.5771\n",
      "Epoch 126/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.8558 - mae: 11.4049\n",
      "Epoch 127/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 225.6265 - mae: 11.9474\n",
      "Epoch 128/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.5884 - mae: 11.5348\n",
      "Epoch 129/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.0628 - mae: 11.3900\n",
      "Epoch 130/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 221.5774 - mae: 11.9707\n",
      "Epoch 131/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.1416 - mae: 11.6056\n",
      "Epoch 132/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.5993 - mae: 11.4708\n",
      "Epoch 133/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 219.9810 - mae: 11.9887\n",
      "Epoch 134/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.9418 - mae: 11.1523\n",
      "Epoch 135/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.7962 - mae: 11.3810\n",
      "Epoch 136/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 226.4250 - mae: 11.9925\n",
      "Epoch 137/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.9261 - mae: 11.1750\n",
      "Epoch 138/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.8520 - mae: 11.5010\n",
      "Epoch 139/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.6454 - mae: 11.8874\n",
      "Epoch 140/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.3211 - mae: 11.5848\n",
      "Epoch 141/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.6897 - mae: 11.6572\n",
      "Epoch 142/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.3593 - mae: 11.4172\n",
      "Epoch 143/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.2292 - mae: 11.5718\n",
      "Epoch 144/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.2830 - mae: 11.5320\n",
      "Epoch 145/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.5642 - mae: 11.4158\n",
      "Epoch 146/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.1490 - mae: 11.2302\n",
      "Epoch 147/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.7420 - mae: 11.5102\n",
      "Epoch 148/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 221.8341 - mae: 11.9027\n",
      "Epoch 149/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.7219 - mae: 11.7603\n",
      "Epoch 150/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.5825 - mae: 11.4602\n",
      "Epoch 151/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.0167 - mae: 11.5799\n",
      "Epoch 152/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.7219 - mae: 11.3903\n",
      "Epoch 153/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.8966 - mae: 11.3918\n",
      "Epoch 154/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 212.5841 - mae: 11.7752\n",
      "Epoch 155/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 197.4362 - mae: 11.2695\n",
      "Epoch 156/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 203.9900 - mae: 11.4305\n",
      "Epoch 157/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.0341 - mae: 11.6183\n",
      "Epoch 158/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.8169 - mae: 11.4748\n",
      "Epoch 159/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.1323 - mae: 11.3301\n",
      "Epoch 160/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 223.8006 - mae: 12.0529\n",
      "Epoch 161/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 219.0638 - mae: 12.0113\n",
      "Epoch 162/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.1170 - mae: 11.3621\n",
      "Epoch 163/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.3222 - mae: 11.4962\n",
      "Epoch 164/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.3924 - mae: 11.2093\n",
      "Epoch 165/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.8548 - mae: 11.7732\n",
      "Epoch 166/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.6058 - mae: 11.6544\n",
      "Epoch 167/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.3394 - mae: 11.5142\n",
      "Epoch 168/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 214.0763 - mae: 11.7367\n",
      "Epoch 169/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.0485 - mae: 11.2733\n",
      "Epoch 170/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.2409 - mae: 11.5461\n",
      "Epoch 171/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 198.3210 - mae: 11.2999\n",
      "Epoch 172/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.9722 - mae: 11.7929\n",
      "Epoch 173/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.6370 - mae: 11.3356\n",
      "Epoch 174/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 202.5678 - mae: 11.5696\n",
      "Epoch 175/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.0102 - mae: 11.6491\n",
      "Epoch 176/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.7431 - mae: 11.3036\n",
      "Epoch 177/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 201.3865 - mae: 11.4665\n",
      "Epoch 178/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 200.9292 - mae: 11.3005\n",
      "Epoch 179/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.3975 - mae: 11.5415\n",
      "Epoch 180/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 205.5553 - mae: 11.3971\n",
      "Epoch 181/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 195.7099 - mae: 11.1899\n",
      "Epoch 182/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 219.3241 - mae: 11.9261\n",
      "Epoch 183/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.1483 - mae: 11.3545\n",
      "Epoch 184/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.2420 - mae: 11.5703\n",
      "Epoch 185/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 211.0426 - mae: 11.7074\n",
      "Epoch 186/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 206.8764 - mae: 11.5466\n",
      "Epoch 187/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 213.5739 - mae: 11.6846\n",
      "Epoch 188/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.5455 - mae: 11.6008\n",
      "Epoch 189/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 199.1013 - mae: 11.4329\n",
      "Epoch 190/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 208.1252 - mae: 11.5780\n",
      "Epoch 191/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 210.7206 - mae: 11.6143\n",
      "Epoch 192/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 196.3676 - mae: 11.1567\n",
      "Epoch 193/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.7774 - mae: 11.5399\n",
      "Epoch 194/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 217.1207 - mae: 12.0179\n",
      "Epoch 195/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 204.0725 - mae: 11.4671\n",
      "Epoch 196/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.5417 - mae: 11.2225\n",
      "Epoch 197/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 195.3510 - mae: 11.1446\n",
      "Epoch 198/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 207.3691 - mae: 11.5559\n",
      "Epoch 199/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.9065 - mae: 11.7259\n",
      "Epoch 200/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 209.8770 - mae: 11.4741\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "RMSE para regressão: 14.376866203733677\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_data = pd.read_csv('treino_sinais_vitais_com_label.csv')\n",
    "test_data = pd.read_csv('treino_sinais_vitais_sem_label.csv')\n",
    "\n",
    "X_train = train_data[[\"si3\", \"si4\", \"si5\"]].values  \n",
    "y_train_gi = train_data[\"gi\"].values  \n",
    "\n",
    "X_test = test_data[[\"si3\", \"si4\", \"si5\"]].values\n",
    "y_test_gi = test_data[\"gi\"].values  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model_regression = Sequential(\n",
    "    [Dense(1, input_dim=3, activation=\"linear\")]  \n",
    ")\n",
    "\n",
    "model_regression.compile(\n",
    "    optimizer=Adam(learning_rate=0.03), loss=\"mse\", metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "model_regression.fit(X_train, y_train_gi, epochs=200, batch_size=10, verbose=1)\n",
    "\n",
    "y_pred_gi = model_regression.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_gi, y_pred_gi))\n",
    "print(f\"RMSE para regressão: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gi</th>\n",
       "      <th>gi_pred</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>47.641941</td>\n",
       "      <td>1.191049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.530426</td>\n",
       "      <td>45.720337</td>\n",
       "      <td>1.100888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.730748</td>\n",
       "      <td>49.429195</td>\n",
       "      <td>0.937388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.679910</td>\n",
       "      <td>41.111912</td>\n",
       "      <td>1.185468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.375881</td>\n",
       "      <td>44.117523</td>\n",
       "      <td>0.635920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>24.494467</td>\n",
       "      <td>38.476479</td>\n",
       "      <td>1.570823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>65.385014</td>\n",
       "      <td>39.187809</td>\n",
       "      <td>0.599339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>24.530703</td>\n",
       "      <td>49.349808</td>\n",
       "      <td>2.011757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>61.062548</td>\n",
       "      <td>43.194950</td>\n",
       "      <td>0.707389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>39.110504</td>\n",
       "      <td>37.398281</td>\n",
       "      <td>0.956221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             gi    gi_pred  percentage\n",
       "0     40.000000  47.641941    1.191049\n",
       "1     41.530426  45.720337    1.100888\n",
       "2     52.730748  49.429195    0.937388\n",
       "3     34.679910  41.111912    1.185468\n",
       "4     69.375881  44.117523    0.635920\n",
       "...         ...        ...         ...\n",
       "1495  24.494467  38.476479    1.570823\n",
       "1496  65.385014  39.187809    0.599339\n",
       "1497  24.530703  49.349808    2.011757\n",
       "1498  61.062548  43.194950    0.707389\n",
       "1499  39.110504  37.398281    0.956221\n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results['gi'] = test_data['gi'].reset_index(drop=True)\n",
    "results['gi_pred'] = y_pred_gi.flatten()\n",
    "\n",
    "results['percentage'] = (results['gi_pred']) / results['gi']\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando rede neural com camadas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teteus/Documents/sistemas_inteligentes/trabalho02/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 805.8064 - mae: 22.2358\n",
      "Epoch 2/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 215.4496 - mae: 11.8103\n",
      "Epoch 3/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 120.7968 - mae: 8.5484\n",
      "Epoch 4/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 102.5739 - mae: 7.8544\n",
      "Epoch 5/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 89.6223 - mae: 7.2610\n",
      "Epoch 6/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 102.3587 - mae: 7.8120\n",
      "Epoch 7/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 92.1329 - mae: 7.3795\n",
      "Epoch 8/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74.2651 - mae: 6.7867\n",
      "Epoch 9/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 45.1068 - mae: 5.1635\n",
      "Epoch 10/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 34.8265 - mae: 4.6100\n",
      "Epoch 11/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.6720 - mae: 3.5637\n",
      "Epoch 12/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3177 - mae: 3.2061\n",
      "Epoch 13/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.4532 - mae: 3.0531\n",
      "Epoch 14/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.7198 - mae: 3.4908\n",
      "Epoch 15/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.5300 - mae: 3.1010\n",
      "Epoch 16/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.2633 - mae: 3.2598\n",
      "Epoch 17/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.9360 - mae: 2.9203\n",
      "Epoch 18/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.7225 - mae: 2.9331\n",
      "Epoch 19/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 13.9538 - mae: 2.8277\n",
      "Epoch 20/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.0177 - mae: 2.9711\n",
      "Epoch 21/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.5945 - mae: 2.7888\n",
      "Epoch 22/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.7358 - mae: 2.5431\n",
      "Epoch 23/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.1119 - mae: 2.5339\n",
      "Epoch 24/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.4542 - mae: 2.7493\n",
      "Epoch 25/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4524 - mae: 2.3541\n",
      "Epoch 26/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6995 - mae: 2.3540\n",
      "Epoch 27/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4002 - mae: 2.4707\n",
      "Epoch 28/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.7709 - mae: 2.6051\n",
      "Epoch 29/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1826 - mae: 2.3366\n",
      "Epoch 30/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.3061 - mae: 3.1727\n",
      "Epoch 31/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.0936 - mae: 2.3905\n",
      "Epoch 32/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3951 - mae: 2.3522\n",
      "Epoch 33/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.9459 - mae: 2.5767\n",
      "Epoch 34/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.8717 - mae: 2.6964\n",
      "Epoch 35/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8306 - mae: 2.3672\n",
      "Epoch 36/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.1892 - mae: 2.4574\n",
      "Epoch 37/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.3046 - mae: 3.0201\n",
      "Epoch 38/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.9784 - mae: 2.7443\n",
      "Epoch 39/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9179 - mae: 2.2014\n",
      "Epoch 40/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4548 - mae: 2.1926\n",
      "Epoch 41/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5750 - mae: 2.3503\n",
      "Epoch 42/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9528 - mae: 1.9690\n",
      "Epoch 43/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.9546 - mae: 2.6121\n",
      "Epoch 44/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4127 - mae: 2.2978\n",
      "Epoch 45/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6100 - mae: 2.2487\n",
      "Epoch 46/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4282 - mae: 2.1557\n",
      "Epoch 47/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7615 - mae: 2.1116\n",
      "Epoch 48/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1210 - mae: 1.8532\n",
      "Epoch 49/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0346 - mae: 1.9859\n",
      "Epoch 50/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4521 - mae: 2.3230\n",
      "Epoch 51/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8362 - mae: 2.2730\n",
      "Epoch 52/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8755 - mae: 1.9976\n",
      "Epoch 53/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8042 - mae: 1.9313\n",
      "Epoch 54/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3884 - mae: 2.3840\n",
      "Epoch 55/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4394 - mae: 2.0884\n",
      "Epoch 56/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0488 - mae: 2.2464\n",
      "Epoch 57/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7809 - mae: 2.1333\n",
      "Epoch 58/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6839 - mae: 1.9276\n",
      "Epoch 59/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7340 - mae: 2.0720\n",
      "Epoch 60/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0029 - mae: 2.0278\n",
      "Epoch 61/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7318 - mae: 2.3075\n",
      "Epoch 62/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8543 - mae: 2.2467\n",
      "Epoch 63/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6121 - mae: 1.7916\n",
      "Epoch 64/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0295 - mae: 1.9934\n",
      "Epoch 65/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5398 - mae: 2.0858\n",
      "Epoch 66/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7120 - mae: 1.8202\n",
      "Epoch 67/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2642 - mae: 1.8500\n",
      "Epoch 68/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2900 - mae: 1.8350\n",
      "Epoch 69/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0405 - mae: 1.8677\n",
      "Epoch 70/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7167 - mae: 1.7768\n",
      "Epoch 71/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4257 - mae: 1.9647\n",
      "Epoch 72/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7902 - mae: 1.9798\n",
      "Epoch 73/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1525 - mae: 2.1551\n",
      "Epoch 74/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4534 - mae: 1.7577\n",
      "Epoch 75/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4731 - mae: 1.7585\n",
      "Epoch 76/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4545 - mae: 2.4080\n",
      "Epoch 77/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0497 - mae: 2.2180\n",
      "Epoch 78/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9255 - mae: 1.6121\n",
      "Epoch 79/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9204 - mae: 1.8191\n",
      "Epoch 80/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4784 - mae: 1.7304\n",
      "Epoch 81/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5251 - mae: 1.7945\n",
      "Epoch 82/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3112 - mae: 1.7118\n",
      "Epoch 83/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2668 - mae: 2.0035\n",
      "Epoch 84/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1643 - mae: 2.0127\n",
      "Epoch 85/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7646 - mae: 1.6317\n",
      "Epoch 86/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7197 - mae: 1.9316\n",
      "Epoch 87/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5837 - mae: 1.7439\n",
      "Epoch 88/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6234 - mae: 1.9121\n",
      "Epoch 89/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5003 - mae: 2.1187\n",
      "Epoch 90/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9362 - mae: 1.6613\n",
      "Epoch 91/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7830 - mae: 1.9734\n",
      "Epoch 92/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9005 - mae: 1.8546\n",
      "Epoch 93/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1217 - mae: 1.8524\n",
      "Epoch 94/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6360 - mae: 2.2028\n",
      "Epoch 95/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6594 - mae: 1.7467\n",
      "Epoch 96/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.0921 - mae: 1.8593\n",
      "Epoch 97/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7229 - mae: 1.6093\n",
      "Epoch 98/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0990 - mae: 1.6858\n",
      "Epoch 99/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0045 - mae: 1.8451\n",
      "Epoch 100/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0275 - mae: 1.6939\n",
      "Epoch 101/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9544 - mae: 1.6801\n",
      "Epoch 102/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6282 - mae: 1.6381\n",
      "Epoch 103/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9217 - mae: 1.9118\n",
      "Epoch 104/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4533 - mae: 1.8576\n",
      "Epoch 105/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7384 - mae: 1.6601\n",
      "Epoch 106/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0350 - mae: 1.7064\n",
      "Epoch 107/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0179 - mae: 1.7783\n",
      "Epoch 108/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8348 - mae: 1.9845\n",
      "Epoch 109/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0741 - mae: 1.6206\n",
      "Epoch 110/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2872 - mae: 1.7022\n",
      "Epoch 111/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1024 - mae: 1.8595\n",
      "Epoch 112/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9433 - mae: 1.4636\n",
      "Epoch 113/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5525 - mae: 1.9052\n",
      "Epoch 114/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7647 - mae: 1.7777\n",
      "Epoch 115/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.3855 - mae: 1.5652\n",
      "Epoch 116/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7302 - mae: 1.9921\n",
      "Epoch 117/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9606 - mae: 1.6725\n",
      "Epoch 118/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6468 - mae: 1.6316\n",
      "Epoch 119/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.8045 - mae: 1.6503 \n",
      "Epoch 120/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.7366 - mae: 2.4244 \n",
      "Epoch 121/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8663 - mae: 1.7991\n",
      "Epoch 122/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6118 - mae: 1.9354\n",
      "Epoch 123/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3465 - mae: 1.7738\n",
      "Epoch 124/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6085 - mae: 1.7752\n",
      "Epoch 125/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9735 - mae: 1.4770\n",
      "Epoch 126/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3900 - mae: 1.7270\n",
      "Epoch 127/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4079 - mae: 1.5330\n",
      "Epoch 128/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0954 - mae: 1.7381\n",
      "Epoch 129/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.4542 - mae: 1.7546\n",
      "Epoch 130/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9451 - mae: 1.8142\n",
      "Epoch 131/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6069 - mae: 1.5951\n",
      "Epoch 132/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4259 - mae: 1.5785\n",
      "Epoch 133/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9673 - mae: 1.6451\n",
      "Epoch 134/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0131 - mae: 1.7173\n",
      "Epoch 135/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.8648 - mae: 1.6138\n",
      "Epoch 136/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7142 - mae: 1.5493\n",
      "Epoch 137/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5266 - mae: 1.5954\n",
      "Epoch 138/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6436 - mae: 1.9911\n",
      "Epoch 139/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3584 - mae: 1.7521\n",
      "Epoch 140/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7450 - mae: 1.5980\n",
      "Epoch 141/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9052 - mae: 1.6425\n",
      "Epoch 142/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.3200 - mae: 1.7384\n",
      "Epoch 143/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2658 - mae: 1.5346\n",
      "Epoch 144/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7869 - mae: 1.6094\n",
      "Epoch 145/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6008 - mae: 1.5769\n",
      "Epoch 146/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3445 - mae: 1.5871\n",
      "Epoch 147/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0786 - mae: 1.7009\n",
      "Epoch 148/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9397 - mae: 1.4640\n",
      "Epoch 149/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5507 - mae: 1.5981\n",
      "Epoch 150/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6097 - mae: 1.5671\n",
      "Epoch 151/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8349 - mae: 1.6443\n",
      "Epoch 152/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1054 - mae: 1.6998\n",
      "Epoch 153/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1687 - mae: 1.6696\n",
      "Epoch 154/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2653 - mae: 1.5120\n",
      "Epoch 155/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0293 - mae: 1.8754\n",
      "Epoch 156/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7920 - mae: 1.6307\n",
      "Epoch 157/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9864 - mae: 1.6820\n",
      "Epoch 158/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6272 - mae: 1.5693\n",
      "Epoch 159/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8568 - mae: 1.4269\n",
      "Epoch 160/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0045 - mae: 1.4981\n",
      "Epoch 161/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4515 - mae: 1.3929\n",
      "Epoch 162/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7489 - mae: 1.6147\n",
      "Epoch 163/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6949 - mae: 1.5994\n",
      "Epoch 164/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0969 - mae: 1.6483\n",
      "Epoch 165/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4718 - mae: 1.9071\n",
      "Epoch 166/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8913 - mae: 1.9361\n",
      "Epoch 167/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9240 - mae: 1.4479\n",
      "Epoch 168/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9100 - mae: 1.5955\n",
      "Epoch 169/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8562 - mae: 1.4327\n",
      "Epoch 170/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2457 - mae: 1.5479\n",
      "Epoch 171/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7515 - mae: 1.4061\n",
      "Epoch 172/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.2728 - mae: 1.3339\n",
      "Epoch 173/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9108 - mae: 1.4726\n",
      "Epoch 174/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4281 - mae: 1.5840\n",
      "Epoch 175/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2370 - mae: 1.7214\n",
      "Epoch 176/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4198 - mae: 1.3284\n",
      "Epoch 177/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3590 - mae: 1.3531\n",
      "Epoch 178/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0928 - mae: 1.5185\n",
      "Epoch 179/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.0926 - mae: 1.6627\n",
      "Epoch 180/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.3241 - mae: 1.3635\n",
      "Epoch 181/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0986 - mae: 1.4637\n",
      "Epoch 182/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6964 - mae: 1.5962\n",
      "Epoch 183/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7929 - mae: 1.6281\n",
      "Epoch 184/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4432 - mae: 1.3469\n",
      "Epoch 185/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8899 - mae: 1.5494\n",
      "Epoch 186/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5861 - mae: 1.6035\n",
      "Epoch 187/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.9080 - mae: 1.2178\n",
      "Epoch 188/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1131 - mae: 1.4823\n",
      "Epoch 189/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8465 - mae: 1.4345\n",
      "Epoch 190/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9425 - mae: 1.4551\n",
      "Epoch 191/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4671 - mae: 1.3779\n",
      "Epoch 192/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1205 - mae: 1.5252\n",
      "Epoch 193/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1446 - mae: 1.7986\n",
      "Epoch 194/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4812 - mae: 1.3787\n",
      "Epoch 195/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4932 - mae: 1.3609\n",
      "Epoch 196/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0486 - mae: 1.2586\n",
      "Epoch 197/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1882 - mae: 1.2759\n",
      "Epoch 198/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3812 - mae: 1.8498\n",
      "Epoch 199/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9839 - mae: 1.4601\n",
      "Epoch 200/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7351 - mae: 1.8873\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Previsões salvas no arquivo 'resultados_preditos.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = pd.read_csv(\"treino_sinais_vitais_com_label.csv\")\n",
    "test_data = pd.read_csv(\"treino_sinais_vitais_sem_label.csv\")\n",
    "\n",
    "X_train = train_data[[\"si3\", \"si4\", \"si5\"]].values\n",
    "y_train_gi = train_data[\"gi\"].values\n",
    "\n",
    "X_test = test_data[[\"si3\", \"si4\", \"si5\"]].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model_regression = Sequential(\n",
    "    [\n",
    "        Dense(64, input_dim=3, activation=\"relu\"),  # Camada oculta com 64 neurônios\n",
    "        Dense(32, activation=\"relu\"),  # Outra camada oculta com 32 neurônios\n",
    "        Dense(1, activation=\"linear\"),  # Camada de saída com 1 neurônio\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_regression.compile(\n",
    "    optimizer=Adam(learning_rate=0.03), loss=\"mse\", metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "history = model_regression.fit(\n",
    "    X_train, y_train_gi, epochs=200, batch_size=16, verbose=1\n",
    ")\n",
    "\n",
    "predicted_gi = model_regression.predict(X_test)\n",
    "\n",
    "results = test_data.copy()\n",
    "results[\"predicted_gi\"] = predicted_gi\n",
    "results.to_csv(\"resultados_preditos.csv\", index=False)\n",
    "\n",
    "print(\"Previsões salvas no arquivo 'resultados_preditos.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>si1</th>\n",
       "      <th>si2</th>\n",
       "      <th>si3</th>\n",
       "      <th>si4</th>\n",
       "      <th>si5</th>\n",
       "      <th>gi</th>\n",
       "      <th>yi</th>\n",
       "      <th>predicted_gi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.592433</td>\n",
       "      <td>12.220855</td>\n",
       "      <td>8.416754</td>\n",
       "      <td>75.921057</td>\n",
       "      <td>21.635259</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.840771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15.775386</td>\n",
       "      <td>13.586879</td>\n",
       "      <td>8.725890</td>\n",
       "      <td>63.813564</td>\n",
       "      <td>19.718734</td>\n",
       "      <td>41.530426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.201286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.649369</td>\n",
       "      <td>1.904802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>197.210213</td>\n",
       "      <td>19.045471</td>\n",
       "      <td>52.730748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.410698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>17.264362</td>\n",
       "      <td>13.700638</td>\n",
       "      <td>8.733333</td>\n",
       "      <td>143.636181</td>\n",
       "      <td>17.621141</td>\n",
       "      <td>34.679910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.086372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>12.705183</td>\n",
       "      <td>9.485389</td>\n",
       "      <td>1.747626</td>\n",
       "      <td>82.636672</td>\n",
       "      <td>12.209535</td>\n",
       "      <td>69.375881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.903801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7.573969</td>\n",
       "      <td>1.463106</td>\n",
       "      <td>-6.541057</td>\n",
       "      <td>19.726047</td>\n",
       "      <td>9.215187</td>\n",
       "      <td>14.247813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.803205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>11.749524</td>\n",
       "      <td>4.177473</td>\n",
       "      <td>-2.937162</td>\n",
       "      <td>146.911825</td>\n",
       "      <td>2.796695</td>\n",
       "      <td>32.957477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.412125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>9.847899</td>\n",
       "      <td>8.203223</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>127.461258</td>\n",
       "      <td>14.401656</td>\n",
       "      <td>71.214749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.974701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>18.143625</td>\n",
       "      <td>14.362603</td>\n",
       "      <td>8.733333</td>\n",
       "      <td>14.768375</td>\n",
       "      <td>19.007228</td>\n",
       "      <td>29.256709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.329866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>19.790224</td>\n",
       "      <td>14.473328</td>\n",
       "      <td>8.733333</td>\n",
       "      <td>24.101633</td>\n",
       "      <td>6.041166</td>\n",
       "      <td>13.222719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.612119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i        si1        si2       si3         si4        si5         gi  yi  \\\n",
       "0   1  13.592433  12.220855  8.416754   75.921057  21.635259  40.000000 NaN   \n",
       "1   2  15.775386  13.586879  8.725890   63.813564  19.718734  41.530426 NaN   \n",
       "2   3   3.649369   1.904802  0.000000  197.210213  19.045471  52.730748 NaN   \n",
       "3   4  17.264362  13.700638  8.733333  143.636181  17.621141  34.679910 NaN   \n",
       "4   5  12.705183   9.485389  1.747626   82.636672  12.209535  69.375881 NaN   \n",
       "5   6   7.573969   1.463106 -6.541057   19.726047   9.215187  14.247813 NaN   \n",
       "6   7  11.749524   4.177473 -2.937162  146.911825   2.796695  32.957477 NaN   \n",
       "7   8   9.847899   8.203223 -0.000000  127.461258  14.401656  71.214749 NaN   \n",
       "8   9  18.143625  14.362603  8.733333   14.768375  19.007228  29.256709 NaN   \n",
       "9  10  19.790224  14.473328  8.733333   24.101633   6.041166  13.222719 NaN   \n",
       "\n",
       "   predicted_gi  \n",
       "0     40.840771  \n",
       "1     42.201286  \n",
       "2     52.410698  \n",
       "3     36.086372  \n",
       "4     69.903801  \n",
       "5     15.803205  \n",
       "6     32.412125  \n",
       "7     71.974701  \n",
       "8     26.329866  \n",
       "9     13.612119  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de previsões dentro da faixa de erro de 10%: 1452\n",
      "Porcentagem de previsões dentro da faixa de erro de 10%: 96.80%\n"
     ]
    }
   ],
   "source": [
    "results['percentage_error'] = abs((results['predicted_gi'] - results['gi']) / results['gi']) * 100\n",
    "\n",
    "within_10_percent = results[results['percentage_error'] <= 10]\n",
    "\n",
    "count_within_10_percent = within_10_percent.shape[0]\n",
    "\n",
    "total_count = results.shape[0]\n",
    "percentage_within_10_percent = (count_within_10_percent / total_count) * 100\n",
    "\n",
    "print(f\"Número de previsões dentro da faixa de erro de 10%: {count_within_10_percent}\")\n",
    "print(f\"Porcentagem de previsões dentro da faixa de erro de 10%: {percentage_within_10_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/teteus/Documents/sistemas_inteligentes/trabalho02/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4588 - loss: 1.0853\n",
      "Epoch 2/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6887 - loss: 0.7323\n",
      "Epoch 3/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7475 - loss: 0.6168\n",
      "Epoch 4/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7604 - loss: 0.5644\n",
      "Epoch 5/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7740 - loss: 0.5150\n",
      "Epoch 6/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7985 - loss: 0.4696\n",
      "Epoch 7/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8076 - loss: 0.4535\n",
      "Epoch 8/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.4399\n",
      "Epoch 9/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.4637\n",
      "Epoch 10/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8405 - loss: 0.4006\n",
      "Epoch 11/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8440 - loss: 0.3876\n",
      "Epoch 12/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8397 - loss: 0.3826\n",
      "Epoch 13/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.3233\n",
      "Epoch 14/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.4824\n",
      "Epoch 15/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8501 - loss: 0.3693\n",
      "Epoch 16/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8679 - loss: 0.3344\n",
      "Epoch 17/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8594 - loss: 0.3522\n",
      "Epoch 18/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8721 - loss: 0.3022\n",
      "Epoch 19/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8787 - loss: 0.3429\n",
      "Epoch 20/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8659 - loss: 0.3085\n",
      "Epoch 21/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8719 - loss: 0.2861\n",
      "Epoch 22/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8538 - loss: 0.3388\n",
      "Epoch 23/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8645 - loss: 0.3390\n",
      "Epoch 24/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.2703\n",
      "Epoch 25/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8921 - loss: 0.3096\n",
      "Epoch 26/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.3692\n",
      "Epoch 27/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8882 - loss: 0.2814\n",
      "Epoch 28/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8641 - loss: 0.2865\n",
      "Epoch 29/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8732 - loss: 0.2986\n",
      "Epoch 30/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.2679\n",
      "Epoch 31/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8836 - loss: 0.3219\n",
      "Epoch 32/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8424 - loss: 0.3963\n",
      "Epoch 33/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8813 - loss: 0.2663\n",
      "Epoch 34/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8839 - loss: 0.2695\n",
      "Epoch 35/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.2515\n",
      "Epoch 36/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8414 - loss: 0.4281\n",
      "Epoch 37/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8882 - loss: 0.2648\n",
      "Epoch 38/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8749 - loss: 0.2828\n",
      "Epoch 39/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.3411\n",
      "Epoch 40/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8760 - loss: 0.2958\n",
      "Epoch 41/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8729 - loss: 0.3048\n",
      "Epoch 42/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 0.2487\n",
      "Epoch 43/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.2878\n",
      "Epoch 44/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8909 - loss: 0.2641\n",
      "Epoch 45/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2222\n",
      "Epoch 46/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8499 - loss: 0.4732\n",
      "Epoch 47/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2039\n",
      "Epoch 48/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.2562\n",
      "Epoch 49/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8684 - loss: 0.3014\n",
      "Epoch 50/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8849 - loss: 0.3071\n",
      "Epoch 51/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8746 - loss: 0.2992\n",
      "Epoch 52/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8698 - loss: 0.3328\n",
      "Epoch 53/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.2837\n",
      "Epoch 54/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8787 - loss: 0.2734\n",
      "Epoch 55/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.2671\n",
      "Epoch 56/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8759 - loss: 0.2779\n",
      "Epoch 57/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.2435\n",
      "Epoch 58/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8845 - loss: 0.2682\n",
      "Epoch 59/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3334\n",
      "Epoch 60/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8800 - loss: 0.2593\n",
      "Epoch 61/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8456 - loss: 0.3730\n",
      "Epoch 62/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.2699\n",
      "Epoch 63/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8791 - loss: 0.2845\n",
      "Epoch 64/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.2573\n",
      "Epoch 65/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8771 - loss: 0.3086\n",
      "Epoch 66/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8856 - loss: 0.3085\n",
      "Epoch 67/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8534 - loss: 0.3437\n",
      "Epoch 68/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8899 - loss: 0.2694\n",
      "Epoch 69/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.2453\n",
      "Epoch 70/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2196\n",
      "Epoch 71/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8735 - loss: 0.2904\n",
      "Epoch 72/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8845 - loss: 0.2935\n",
      "Epoch 73/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.2596\n",
      "Epoch 74/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8888 - loss: 0.2703\n",
      "Epoch 75/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8790 - loss: 0.2948\n",
      "Epoch 76/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.3277\n",
      "Epoch 77/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8765 - loss: 0.2973\n",
      "Epoch 78/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8897 - loss: 0.2590\n",
      "Epoch 79/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.2396\n",
      "Epoch 80/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.2665\n",
      "Epoch 81/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8841 - loss: 0.3113\n",
      "Epoch 82/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.3021\n",
      "Epoch 83/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8877 - loss: 0.2400\n",
      "Epoch 84/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8835 - loss: 0.3040\n",
      "Epoch 85/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8962 - loss: 0.2509\n",
      "Epoch 86/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8641 - loss: 0.3026\n",
      "Epoch 87/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8851 - loss: 0.3003\n",
      "Epoch 88/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.3407\n",
      "Epoch 89/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9029 - loss: 0.2275\n",
      "Epoch 90/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8615 - loss: 0.3332\n",
      "Epoch 91/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8755 - loss: 0.2877\n",
      "Epoch 92/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8820 - loss: 0.3112\n",
      "Epoch 93/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.3007\n",
      "Epoch 94/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8980 - loss: 0.2831\n",
      "Epoch 95/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9057 - loss: 0.2637\n",
      "Epoch 96/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8971 - loss: 0.2432\n",
      "Epoch 97/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8785 - loss: 0.3027\n",
      "Epoch 98/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.2485\n",
      "Epoch 99/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.2828\n",
      "Epoch 100/100\n",
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8690 - loss: 0.3204\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8503 - loss: 0.4094  \n",
      "Loss: 0.4164, Accuracy: 0.8514\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Resultados salvos no arquivo 'classificacao_resultados.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "data = pd.read_csv(\"treino_sinais_vitais_com_label.csv\")\n",
    "\n",
    "X = data[[\"si3\", \"si4\", \"si5\"]].values\n",
    "y = data[\"yi\"].values  \n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.35, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model_classification = Sequential(\n",
    "    [\n",
    "        Dense(64, input_dim=3, activation=\"relu\"),  # Camada oculta com 64 neurônios\n",
    "        Dense(32, activation=\"relu\"),  # Outra camada oculta com 32 neurônios\n",
    "        Dense(\n",
    "            4, activation=\"softmax\"\n",
    "        ),  # Camada de saída com 4 neurônios (uma para cada classe)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_classification.compile(\n",
    "    optimizer=Adam(learning_rate=0.03),\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model_classification.fit(\n",
    "    X_train, y_train, epochs=100, batch_size=8, verbose=1\n",
    ")\n",
    "\n",
    "loss, accuracy = model_classification.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "predicted_classes = model_classification.predict(X_test)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_classes.argmax(axis=1))\n",
    "\n",
    "test_results = pd.DataFrame(X_test, columns=[\"si3\", \"si4\", \"si5\"])\n",
    "test_results[\"true_class\"] = label_encoder.inverse_transform(y_test)\n",
    "test_results[\"predicted_class\"] = predicted_labels\n",
    "test_results.to_csv(\"classificacao_resultados.csv\", index=False)\n",
    "\n",
    "print(\"Resultados salvos no arquivo 'classificacao_resultados.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gerar a matriz de confusão\n",
    "cm = confusion_matrix(y_test, predicted_classes.argmax(axis=1))\n",
    "\n",
    "# Plotar a matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.xlabel(\"Classe Predita\")\n",
    "plt.ylabel(\"Classe Real\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
